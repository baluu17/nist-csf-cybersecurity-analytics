{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d103c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "678d45d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(529918, 79) (445909, 79) (225745, 79)\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \".\"\n",
    "\n",
    "FILES = {\n",
    "    \"monday\": \"Monday-WorkingHours.pcap_ISCX.csv\",\n",
    "    \"tuesday\": \"Tuesday-WorkingHours.pcap_ISCX.csv\",\n",
    "    \"friday\": \"Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\",\n",
    "}\n",
    "\n",
    "def load_csv(path: str) -> pd.DataFrame:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"File not found: {os.path.abspath(path)}\")\n",
    "    return pd.read_csv(path, low_memory=True)\n",
    "\n",
    "paths = {k: os.path.join(DATA_DIR, v) for k, v in FILES.items()}\n",
    "\n",
    "df_mon_raw = load_csv(paths[\"monday\"])\n",
    "df_tue_raw = load_csv(paths[\"tuesday\"])\n",
    "df_fri_raw = load_csv(paths[\"friday\"])\n",
    "\n",
    "print(df_mon_raw.shape, df_tue_raw.shape, df_fri_raw.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a16de1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example columns (after strip):\n",
      "Index(['Destination Port', 'Flow Duration', 'Total Fwd Packets',\n",
      "       'Total Backward Packets', 'Total Length of Fwd Packets',\n",
      "       'Total Length of Bwd Packets', 'Fwd Packet Length Max',\n",
      "       'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
      "       'Fwd Packet Length Std'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def clean_column_names(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "df_mon = clean_column_names(df_mon_raw)\n",
    "df_tue = clean_column_names(df_tue_raw)\n",
    "df_fri = clean_column_names(df_fri_raw)\n",
    "\n",
    "print(\"Example columns (after strip):\")\n",
    "print(df_mon.columns[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9675260e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns consistent across all three: 79\n",
      "Label column found ✅\n"
     ]
    }
   ],
   "source": [
    "# Columns must match\n",
    "assert list(df_mon.columns) == list(df_tue.columns) == list(df_fri.columns), \"Columns do not match across files.\"\n",
    "\n",
    "# Label column check\n",
    "assert \"Label\" in df_mon.columns, \"Label column not found after cleaning column names.\"\n",
    "\n",
    "print(\"Columns consistent across all three:\", df_mon.shape[1])\n",
    "print(\"Label column found ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a72d743d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: inf handled and numeric coercion attempted.\n"
     ]
    }
   ],
   "source": [
    "def replace_inf_and_coerce_numeric(df: pd.DataFrame, label_col: str = \"Label\") -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # Replace inf/-inf with NaN first (safer), then handle NaNs later\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    # Try to coerce all non-label columns to numeric where possible\n",
    "    feature_cols = [c for c in df.columns if c != label_col]\n",
    "    for c in feature_cols:\n",
    "        # If column is already numeric, this is fast. If it is object, this will attempt conversion.\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    return df\n",
    "\n",
    "df_mon = replace_inf_and_coerce_numeric(df_mon)\n",
    "df_tue = replace_inf_and_coerce_numeric(df_tue)\n",
    "df_fri = replace_inf_and_coerce_numeric(df_fri)\n",
    "\n",
    "print(\"Done: inf handled and numeric coercion attempted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "428447cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top missing columns (Monday):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Flow Packets/s</th>\n",
       "      <td>437</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flow Bytes/s</th>\n",
       "      <td>437</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Destination Port</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Packet Size</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fwd Avg Bulk Rate</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fwd Avg Packets/Bulk</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fwd Avg Bytes/Bulk</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fwd Header Length.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg Bwd Segment Size</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg Fwd Segment Size</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Down/Up Ratio</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bwd Avg Packets/Bulk</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECE Flag Count</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CWE Flag Count</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URG Flag Count</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      missing_count  missing_pct\n",
       "Flow Packets/s                  437        0.082\n",
       "Flow Bytes/s                    437        0.082\n",
       "Destination Port                  0        0.000\n",
       "Average Packet Size               0        0.000\n",
       "Fwd Avg Bulk Rate                 0        0.000\n",
       "Fwd Avg Packets/Bulk              0        0.000\n",
       "Fwd Avg Bytes/Bulk                0        0.000\n",
       "Fwd Header Length.1               0        0.000\n",
       "Avg Bwd Segment Size              0        0.000\n",
       "Avg Fwd Segment Size              0        0.000\n",
       "Down/Up Ratio                     0        0.000\n",
       "Bwd Avg Packets/Bulk              0        0.000\n",
       "ECE Flag Count                    0        0.000\n",
       "CWE Flag Count                    0        0.000\n",
       "URG Flag Count                    0        0.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def missing_report(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rep = pd.DataFrame({\n",
    "        \"missing_count\": df.isna().sum(),\n",
    "        \"missing_pct\": (df.isna().mean() * 100).round(3)\n",
    "    }).sort_values(\"missing_pct\", ascending=False)\n",
    "    return rep\n",
    "\n",
    "miss_mon = missing_report(df_mon)\n",
    "miss_tue = missing_report(df_tue)\n",
    "miss_fri = missing_report(df_fri)\n",
    "\n",
    "print(\"Top missing columns (Monday):\")\n",
    "display(miss_mon.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f92a4ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns count: 10\n",
      "Dropped columns (first 20): ['Bwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd PSH Flags', 'Bwd URG Flags', 'CWE Flag Count', 'Fwd Avg Bulk Rate', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd URG Flags']\n",
      "New column count: 69\n"
     ]
    }
   ],
   "source": [
    "def drop_all_nan_and_constant(df: pd.DataFrame, label_col: str = \"Label\"):\n",
    "    df = df.copy()\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c != label_col]\n",
    "\n",
    "    # Drop columns that are all NaN\n",
    "    all_nan_cols = [c for c in feature_cols if df[c].isna().all()]\n",
    "\n",
    "    # Drop constant columns (nunique ignoring NaN <= 1)\n",
    "    constant_cols = [c for c in feature_cols if df[c].nunique(dropna=True) <= 1]\n",
    "\n",
    "    drop_cols = sorted(set(all_nan_cols + constant_cols))\n",
    "    df.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "    return df, drop_cols\n",
    "\n",
    "df_mon, dropped_cols = drop_all_nan_and_constant(df_mon)\n",
    "df_tue = df_tue.drop(columns=dropped_cols)\n",
    "df_fri = df_fri.drop(columns=dropped_cols)\n",
    "\n",
    "print(\"Dropped columns count:\", len(dropped_cols))\n",
    "print(\"Dropped columns (first 20):\", dropped_cols[:20])\n",
    "print(\"New column count:\", df_mon.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "815d3aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs after filling (Monday): 0\n",
      "NaNs after filling (Tuesday): 0\n",
      "NaNs after filling (Friday): 0\n"
     ]
    }
   ],
   "source": [
    "def fill_nans_with_median(df: pd.DataFrame, label_col: str = \"Label\") -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    feature_cols = [c for c in df.columns if c != label_col]\n",
    "\n",
    "    medians = df[feature_cols].median(numeric_only=True)\n",
    "    df[feature_cols] = df[feature_cols].fillna(medians)\n",
    "\n",
    "    # If any NaNs still exist (rare), fill with 0\n",
    "    df[feature_cols] = df[feature_cols].fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_mon = fill_nans_with_median(df_mon)\n",
    "df_tue = fill_nans_with_median(df_tue)\n",
    "df_fri = fill_nans_with_median(df_fri)\n",
    "\n",
    "print(\"NaNs after filling (Monday):\", int(df_mon.isna().sum().sum()))\n",
    "print(\"NaNs after filling (Tuesday):\", int(df_tue.isna().sum().sum()))\n",
    "print(\"NaNs after filling (Friday):\", int(df_fri.isna().sum().sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fca605d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monday is_attack %: 0.0\n",
      "Tuesday is_attack %: 3.103\n",
      "Friday is_attack %: 56.713\n"
     ]
    }
   ],
   "source": [
    "def clean_labels(df: pd.DataFrame, label_col: str = \"Label\") -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[label_col] = df[label_col].astype(str).str.strip()\n",
    "    df[\"is_attack\"] = (df[label_col].str.upper() != \"BENIGN\").astype(int)\n",
    "    return df\n",
    "\n",
    "df_mon = clean_labels(df_mon)\n",
    "df_tue = clean_labels(df_tue)\n",
    "df_fri = clean_labels(df_fri)\n",
    "\n",
    "print(\"Monday is_attack %:\", round(df_mon[\"is_attack\"].mean()*100, 3))\n",
    "print(\"Tuesday is_attack %:\", round(df_tue[\"is_attack\"].mean()*100, 3))\n",
    "print(\"Friday is_attack %:\", round(df_fri[\"is_attack\"].mean()*100, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15f9421a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monday => features: 68 | NaNs: 0 | Infs: 0\n",
      "Tuesday => features: 68 | NaNs: 0 | Infs: 0\n",
      "Friday => features: 68 | NaNs: 0 | Infs: 0\n"
     ]
    }
   ],
   "source": [
    "def sanity_check(df: pd.DataFrame, label_col: str = \"Label\"):\n",
    "    feature_cols = [c for c in df.columns if c not in [label_col, \"is_attack\"]]\n",
    "    # check NaNs\n",
    "    total_nans = int(df[feature_cols].isna().sum().sum())\n",
    "    # check inf\n",
    "    total_infs = int(np.isinf(df[feature_cols].to_numpy()).sum())\n",
    "    return total_nans, total_infs, len(feature_cols)\n",
    "\n",
    "for name, d in [(\"Monday\", df_mon), (\"Tuesday\", df_tue), (\"Friday\", df_fri)]:\n",
    "    nans, infs, nfeat = sanity_check(d)\n",
    "    print(name, \"=> features:\", nfeat, \"| NaNs:\", nans, \"| Infs:\", infs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "812675c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      ".\\processed\\monday_clean.csv\n",
      ".\\processed\\tuesday_clean.csv\n",
      ".\\processed\\friday_clean.csv\n"
     ]
    }
   ],
   "source": [
    "PROCESSED_DIR = os.path.join(\".\", \"processed\")\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "out_mon = os.path.join(PROCESSED_DIR, \"monday_clean.csv\")\n",
    "out_tue = os.path.join(PROCESSED_DIR, \"tuesday_clean.csv\")\n",
    "out_fri = os.path.join(PROCESSED_DIR, \"friday_clean.csv\")\n",
    "\n",
    "df_mon.to_csv(out_mon, index=False)\n",
    "df_tue.to_csv(out_tue, index=False)\n",
    "df_fri.to_csv(out_fri, index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(out_mon)\n",
    "print(out_tue)\n",
    "print(out_fri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "116119e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>rows</th>\n",
       "      <th>cols</th>\n",
       "      <th>attack_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>monday</td>\n",
       "      <td>529918</td>\n",
       "      <td>70</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tuesday</td>\n",
       "      <td>445909</td>\n",
       "      <td>70</td>\n",
       "      <td>3.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>friday</td>\n",
       "      <td>225745</td>\n",
       "      <td>70</td>\n",
       "      <td>56.713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset    rows  cols  attack_pct\n",
       "0   monday  529918    70       0.000\n",
       "1  tuesday  445909    70       3.103\n",
       "2   friday  225745    70      56.713"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pd.DataFrame({\n",
    "    \"dataset\": [\"monday\", \"tuesday\", \"friday\"],\n",
    "    \"rows\": [len(df_mon), len(df_tue), len(df_fri)],\n",
    "    \"cols\": [df_mon.shape[1], df_tue.shape[1], df_fri.shape[1]],\n",
    "    \"attack_pct\": [\n",
    "        round(df_mon[\"is_attack\"].mean()*100, 3),\n",
    "        round(df_tue[\"is_attack\"].mean()*100, 3),\n",
    "        round(df_fri[\"is_attack\"].mean()*100, 3),\n",
    "    ]\n",
    "})\n",
    "summary\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
